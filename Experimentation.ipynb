{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Experimentation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Import Relevant Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Webpage for a date's (say 4th October 2024) daily papers has the format: https://huggingface.co/papers?date=2024-10-04\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/papers/2410.02740\n",
      "PDF link not found for: Revisit Large-Scale Image-Caption Data in Pre-training Multimodal Foundation Models\n",
      "/papers/2410.02713\n",
      "PDF link not found for: Video Instruction Tuning With Synthetic Data\n",
      "/papers/2410.02757\n",
      "PDF link not found for: Loong: Generating Minute-level Long Videos with Autoregressive Language Models\n",
      "/papers/2410.02712\n",
      "PDF link not found for: LLaVA-Critic: Learning to Evaluate Multimodal Models\n",
      "/papers/2410.02746\n",
      "PDF link not found for: Contrastive Localized Language-Image Pre-Training\n",
      "/papers/2410.02073\n",
      "PDF link not found for: Depth Pro: Sharp Monocular Metric Depth in Less Than a Second\n",
      "/papers/2410.01679\n",
      "PDF link not found for: VinePPO: Unlocking RL Potential For LLM Reasoning Through Refined Credit Assignment\n",
      "/papers/2410.02724\n",
      "PDF link not found for: Large Language Models as Markov Chains\n",
      "/papers/2410.02678\n",
      "PDF link not found for: Distilling an End-to-End Voice Assistant Without Instruction Training Data\n",
      "/papers/2410.02416\n",
      "PDF link not found for: Eliminating Oversaturation and Artifacts of High Guidance Scales in Diffusion Models\n",
      "/papers/2409.19291\n",
      "PDF link not found for: CLIP-MoE: Towards Building Mixture of Experts for CLIP with Diversified Multiplet Upcycling\n",
      "/papers/2410.02749\n",
      "PDF link not found for: Training Language Models on Synthetic Edit Sequences Improves Code Synthesis\n",
      "/papers/2410.02367\n",
      "PDF link not found for: SageAttention: Accurate 8-Bit Attention for Plug-and-play Inference Acceleration\n",
      "/papers/2410.02103\n",
      "PDF link not found for: MVGS: Multi-view-regulated Gaussian Splatting for Novel View Synthesis\n",
      "/papers/2410.02115\n",
      "PDF link not found for: L-CiteEval: Do Long-Context Models Truly Leverage Context for Responding?\n",
      "/papers/2410.02763\n",
      "PDF link not found for: Vinoground: Scrutinizing LMMs over Dense Temporal Reasoning with Short Videos\n",
      "/papers/2410.02458\n",
      "PDF link not found for: MedVisionLlama: Leveraging Pre-Trained Large Language Model Layers to Enhance Medical Image Segmentation\n",
      "/papers/2410.02762\n",
      "PDF link not found for: Interpreting and Editing Vision-Language Representations to Mitigate Hallucinations\n",
      "/papers/2410.02052\n",
      "PDF link not found for: Improving Autonomous AI Agents with Reflective Tree Search and Self-Learning\n",
      "/papers/2410.02536\n",
      "PDF link not found for: Intelligence at the Edge of Chaos\n",
      "/papers/2410.02426\n",
      "PDF link not found for: Learning the Latent Rules of a Game from Data: A Chess Story\n",
      "/papers/2410.02056\n",
      "PDF link not found for: Synthio: Augmenting Small-Scale Audio Classification Datasets with Synthetic Data\n",
      "/papers/2410.02525\n",
      "PDF link not found for: Contextual Document Embeddings\n",
      "/papers/2410.01335\n",
      "PDF link not found for: Layer Swapping for Zero-Shot Cross-Lingual Transfer in Large Language Models\n",
      "/papers/2410.01946\n",
      "PDF link not found for: SciPrompt: Knowledge-augmented Prompting for Fine-grained Categorization of Scientific Topics\n",
      "/papers/2410.00255\n",
      "PDF link not found for: Robin3D: Improving 3D Large Language Model via Robust Instruction Tuning\n",
      "/papers/2410.01782\n",
      "PDF link not found for: Open-RAG: Enhanced Retrieval-Augmented Reasoning with Open-Source Large Language Models\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "\n",
    "# Base URL for Hugging Face\n",
    "BASE_URL = \"https://huggingface.co\"\n",
    "\n",
    "# URL for the Hugging Face daily papers page (update this to the correct page)\n",
    "URL = f\"{BASE_URL}/papers?date=2024-10-04\"\n",
    "\n",
    "# Function to extract PDF links from individual paper page\n",
    "def get_pdf_link(paper_page_url):\n",
    "    # Fetch the paper's page content\n",
    "    paper_response = requests.get(paper_page_url)\n",
    "    \n",
    "    # Parse the paper's page content\n",
    "    if paper_response.status_code == 200:\n",
    "        paper_soup = BeautifulSoup(paper_response.content, 'html.parser')\n",
    "        \n",
    "        # Find the PDF link on the paper's page\n",
    "        # Assuming the PDF link is in an <a> tag with 'href' that contains '.pdf'\n",
    "        pdf_link = paper_soup.find('a', href=lambda href: href and \".pdf\" in href)\n",
    "        \n",
    "        if pdf_link:\n",
    "            return pdf_link['href']  # Return the PDF link\n",
    "    return None\n",
    "\n",
    "# Function to download the PDF file\n",
    "def download_pdf(pdf_url, paper_title):\n",
    "    # Get the PDF content\n",
    "    pdf_response = requests.get(pdf_url)\n",
    "    \n",
    "    if pdf_response.status_code == 200:\n",
    "        # Define the PDF file name, making it a valid file name\n",
    "        paper_title = paper_title.replace(\"/\", \"-\").replace(\"\\\\\", \"-\")  # Clean file name\n",
    "        pdf_file_name = f\"{paper_title}.pdf\"\n",
    "        \n",
    "        # Write the PDF content to a file\n",
    "        with open(pdf_file_name, 'wb') as f:\n",
    "            f.write(pdf_response.content)\n",
    "        print(f\"Downloaded: {pdf_file_name}\")\n",
    "    else:\n",
    "        print(f\"Failed to download PDF: {pdf_url}\")\n",
    "\n",
    "# Step 1: Scrape the daily papers page for paper links\n",
    "response = requests.get(URL)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    # Parse the main daily papers page\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    \n",
    "    # Find all the paper links\n",
    "    # We are looking for <a> tags with the given class attributes in the example you shared\n",
    "    paper_links = soup.find_all('a', class_='line-clamp-3 cursor-pointer text-balance')\n",
    "    \n",
    "    for paper in paper_links:\n",
    "        paper_title = paper.text.strip()  # Get the title of the paper\n",
    "        paper_page_url = paper['href']   # Get the relative link to the paper's Hugging Face page\n",
    "\n",
    "        print(paper_page_url)\n",
    "        \n",
    "        # Ensure the link is a full URL\n",
    "        paper_page_url = f\"{BASE_URL}{paper_page_url}\"\n",
    "        \n",
    "        # Step 2: Visit each paper's Hugging Face page to extract the PDF link\n",
    "        pdf_link = get_pdf_link(paper_page_url)\n",
    "        \n",
    "        if pdf_link:\n",
    "            # Step 3: Download the PDF\n",
    "            download_pdf(pdf_link, paper_title)\n",
    "        else:\n",
    "            print(f\"PDF link not found for: {paper_title}\")\n",
    "else:\n",
    "    print(f\"Failed to retrieve the page. Status code: {response.status_code}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
